{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Classification using Neural Net / MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from converter import * \n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "data = np.load('data_processed/chunk1.npy')\n",
    "data = pd.DataFrame(data).as_matrix()\n",
    "labels = labels_to_numeric(data[:,60])\n",
    "data[:,60] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-546.3631938194943, 116.98695573835903, -4.861569329175866, ...,\n",
       "        0.9078297873738591, -1.749434573764696, 0],\n",
       "       [-562.0175695749476, 128.08630421054093, 1.5521094186028215, ...,\n",
       "        0.13435586288506007, -0.5028825165831374, 14],\n",
       "       [-768.0485577412256, 90.00203429194795, 28.85907213562754, ...,\n",
       "        0.2050543431615374, 0.2356009427612622, 8],\n",
       "       ..., \n",
       "       [-590.1165858091811, 137.36530414141032, 27.38342805707573, ...,\n",
       "        0.2277344734054592, 0.5351962088664386, 2],\n",
       "       [-478.7168919525388, 75.35484879768894, 60.23120923626227, ...,\n",
       "        0.26970327531627797, 0.7025104029473643, 2],\n",
       "       [-502.6165625444437, 169.57863313700733, 6.561729465612, ...,\n",
       "        0.7661254059566451, -0.14261218844844656, 12]], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_trial(classifier, data, normalizer=None):\n",
    "    x = np.array(data[:,:60], dtype=np.float64)\n",
    "    y = np.array(data[:,60], dtype=np.int)\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y)\n",
    "    \n",
    "    if normalizer:\n",
    "        normalizer.fit(train_x)\n",
    "        train_x = normalizer.transform(train_x)\n",
    "        test_x = normalizer.transform(test_x)\n",
    "        \n",
    "    classifier.fit(train_x, train_y)\n",
    "    pred_y = classifier.predict(test_x)\n",
    "    print(\"Generalized Accuracy: \", metrics.accuracy_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 1 \n",
    "- <b>Arhitecture:</b> 2 hidden layers (60 x 60)\n",
    "- <b>Optimizer:</b> LBFGS\n",
    "- <b>Activation function:</b> ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Accuracy:  0.49424\n"
     ]
    }
   ],
   "source": [
    "net = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(60,60), random_state=1)\n",
    "perform_trial(net, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 2 \n",
    "- <b>Arhitecture:</b> 3 hidden layers (120 x 100 x 30)\n",
    "- <b>Optimizer:</b> SGD\n",
    "- <b>Activation function:</b> ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Accuracy:  0.0666\n"
     ]
    }
   ],
   "source": [
    "net = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(120,100,30), random_state=1)\n",
    "perform_trial(net, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 3\n",
    "- <b>Arhitecture:</b> 4 hidden layers (60 x 60 x 60 x 60)\n",
    "- <b>Optimizer:</b> ADAM\n",
    "- <b>Activation function:</b> Logistic / Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Accuracy:  0.72724\n"
     ]
    }
   ],
   "source": [
    "net = MLPClassifier(activation='logistic', solver='adam', alpha=1e-5, hidden_layer_sizes=(60,60,60,60), random_state=1)\n",
    "perform_trial(net, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 4 \n",
    "- <b>Arhitecture:</b> 3 hidden layers (120 x 100 x 120)\n",
    "- <b>Optimizer:</b> ADAM\n",
    "- <b>Activation function:</b> ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Accuracy:  0.76152\n"
     ]
    }
   ],
   "source": [
    "net = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(120,100,120), random_state=1)\n",
    "perform_trial(net, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 5\n",
    "- <b>Arhitecture:</b> 3 hidden layers (180 x 120 x 60)\n",
    "- <b>Optimizer:</b> ADAM\n",
    "- <b>Activation function:</b> ReLU\n",
    "- <b>Learning rate:</b> 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Accuracy:  0.74\n"
     ]
    }
   ],
   "source": [
    "net = MLPClassifier(activation='relu', solver='adam', learning_rate_init=0.003, alpha=1e-5, \n",
    "                    hidden_layer_sizes=(180,120,60), random_state=1)\n",
    "perform_trial(net, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 6: MinMax Normalization [-1,1]\n",
    "- Same parameters as for Trial 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Accuracy:  0.77144\n"
     ]
    }
   ],
   "source": [
    "net = MLPClassifier(activation='relu', solver='adam', learning_rate_init=0.003, alpha=1e-5, \n",
    "                    hidden_layer_sizes=(180,120,60), random_state=1)\n",
    "perform_trial(net, data, normalizer=MinMaxScaler(feature_range=(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 7: RobustScaler Normalization [-1,1]\n",
    "- Same parameters as for Trial 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Accuracy:  0.77164\n"
     ]
    }
   ],
   "source": [
    "net = MLPClassifier(activation='relu', solver='adam', learning_rate_init=0.003, alpha=1e-5, \n",
    "                    hidden_layer_sizes=(180,120,60), random_state=1)\n",
    "perform_trial(net, data, normalizer=RobustScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on the entire data set\n",
    "\n",
    "For this, we need to import all the data and train the neural net based on the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = 'data_processed/'\n",
    "data_files = os.listdir(FOLDER)\n",
    "\n",
    "data_all = []\n",
    "for file in data_files:\n",
    "    data_chunk = np.load(FOLDER + file)\n",
    "    try:\n",
    "        data_all = np.concatenate([data_all, data_chunk], axis=0)\n",
    "    except TypeError:\n",
    "        data_all = data_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.DataFrame(data_all).as_matrix()\n",
    "labels_all = labels_to_numeric(data_all[:,60])\n",
    "data_all[:,60] = labels_all\n",
    "data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with the best candidate - from Trial 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLPClassifier(activation='relu', solver='adam', learning_rate_init=0.003, alpha=1e-5, \n",
    "                    hidden_layer_sizes=(180,120,60), random_state=1)\n",
    "scaler = RobustScaler()\n",
    "perform_trial(net, data_all, normalizer=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
